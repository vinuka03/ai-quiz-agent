Hereâ€™s a complete and polished **README.md** file for your AI-Powered Quiz Generator project, tailored for GitHub:

---

````markdown
# ğŸ§  AI-Powered Quiz Generator (RAG + Gemma 2B + React + FastAPI)

A full-stack web application that automatically generates short quizzes from uploaded PDF or TXT files using **Retrieval-Augmented Generation (RAG)** and a **locally hosted Gemma 2B** model via Ollama. Ideal for educators, students, and lifelong learners who want to test knowledge from educational materials.

---

## ğŸš€ Features

- ğŸ“„ **Smart Upload**: Accepts `.pdf` and `.txt` files with a max size of **5MB**.
- âš™ï¸ **Text Chunking & Embedding**: Documents are split into semantic chunks and embedded using SentenceTransformers.
- ğŸ” **RAG-based Question Generation**:
  - Relevant chunks are **retrieved** from ChromaDB using LangChain.
  - The retrieved context is sent to a **locally hosted LLM (Gemma 2B)** to generate quiz questions.
- ğŸ¯ **Customizable Quizzes**: Choose between **5 or 10 questions**.
- ğŸ§  **Live Feedback**: UI shows progress like â€œExtractingâ€¦â€ and â€œGeneratingâ€¦â€.
- ğŸ“¥ **Export Ready**: Clean quiz output with a PDF download feature coming soon.
- ğŸ’» **Fully Local**: Runs entirely offline â€” no API keys, no cloud dependency.

---

## ğŸ›  Tech Stack

### ğŸ”¹ Frontend
- React (Vite)
- Vanilla CSS
- Axios

### ğŸ”¹ Backend
- FastAPI
- PyMuPDF (PDF text extraction)
- LangChain
- ChromaDB
- SentenceTransformers

### ğŸ”¹ LLM
- Gemma 2B (via [Ollama](https://ollama.com))

---

## ğŸ“¦ Setup Instructions

### 1. Clone the repository
```bash
git clone https://github.com/yourusername/ai-quiz-generator.git
cd ai-quiz-generator
````

### 2. Backend Setup (Python)

```bash
cd backend
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows
pip install -r requirements.txt
```

Make sure **Ollama** is running and you have pulled the Gemma 2B model:

```bash
ollama run gemma2:2b
```

Then start the backend:

```bash
uvicorn main:app --reload
```

### 3. Frontend Setup (React)

```bash
cd ../frontend
npm install
npm run dev
```

---



## ğŸ§  About RAG

**Retrieval-Augmented Generation (RAG)** is a hybrid architecture where relevant information is retrieved from a knowledge base (here, ChromaDB) and used to ground the response generation from an LLM. In this app:

* User uploads a file â†’ it's chunked and embedded.
* A sample of the document is used to retrieve relevant sections.
* The retrieved context is passed to **Gemma 2B**, ensuring **contextually accurate, document-grounded questions**.

---



---

## ğŸ™Œ Acknowledgements

* [LangChain](https://www.langchain.com/)
* [Ollama](https://ollama.com/)
* [ChromaDB](https://www.trychroma.com/)
* [SentenceTransformers](https://www.sbert.net/)

```

---

Let me know if you want me to auto-generate a `requirements.txt` or project folder structure as well.
```

